{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4HrTtNZU7hFD",
        "dAhBo5u9HmUz",
        "ewH5wfMhHtBs",
        "Fu-FVloB7v5M",
        "NmP8KT3G702F",
        "b5jN-k9G8Lnp",
        "xw8nIWNt8djz",
        "qyOBahMK_SJa"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# G1"
      ],
      "metadata": {
        "id": "4HrTtNZU7hFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependências"
      ],
      "metadata": {
        "id": "0BvHgbmOIJrT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHq_FvDoAqW5",
        "outputId": "851cadf3-bb36-4dc3-e21f-20c7b862feb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.38.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting webdriver-manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Collecting trio<1.0,>=0.31.0 (from selenium)\n",
            "  Downloading trio-0.32.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2025.10.5 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.11.12)\n",
            "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.15.0)\n",
            "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (2.32.4)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (1.2.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (25.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n",
            "Collecting outcome (from trio<1.0,>=0.31.0->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n",
            "  Downloading wsproto-1.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->webdriver-manager) (3.4.4)\n",
            "Requirement already satisfied: h11<1,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
            "Downloading selenium-4.38.0-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading trio-0.32.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.0/512.0 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.3.2-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, outcome, webdriver-manager, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.38.0 trio-0.32.0 trio-websocket-0.12.2 webdriver-manager-4.0.2 wsproto-1.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium webdriver-manager"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coleta de Dados"
      ],
      "metadata": {
        "id": "dAhBo5u9HmUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# PASSO 1: INSTALAÇÃO DE DEPENDÊNCIAS DO SCRAPING\n",
        "# ----------------------------------------------------------------------\n",
        "print(\"--- [SETUP] Instalando dependências do sistema e do Python ---\")\n",
        "!apt-get update -qq > /dev/null\n",
        "!apt-get install -y libvulkan1 libglib2.0-0 libnss3 libgconf-2-4 libfontconfig1 -qq > /dev/null\n",
        "!wget -q https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!dpkg -i google-chrome-stable_current_amd64.deb > /dev/null\n",
        "!pip install pandas beautifulsoup4 selenium webdriver-manager pytz -q\n",
        "print(\"--- [SETUP] Instalação concluída ---\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# PASSO 2: IMPORTAÇÕES E CONFIGURAÇÃO\n",
        "# ----------------------------------------------------------------------\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "from urllib.parse import urljoin, quote\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pytz\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException\n",
        "\n",
        "print(\"\\n--- [INIT] Fase 1: Bibliotecas importadas ---\")\n",
        "\n",
        "BR_TIMEZONE = pytz.timezone('America/Sao_Paulo')\n",
        "query_busca = \"defesa civil campinas piracicaba\"\n",
        "URL_G1_BASE = f\"https://g1.globo.com/busca/?q={quote(query_busca)}&order=recent&period=7d\"\n",
        "HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
        "dados_coletados = []\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# PASSO 3: FUNÇÕES DE SCRAPING (APRIMORADAS)\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "def setup_driver():\n",
        "    \"\"\"Configura o WebDriver com opções anti-detecção.\"\"\"\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    options.add_argument(f'user-agent={HEADERS[\"User-Agent\"]}')\n",
        "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
        "    options.add_experimental_option('useAutomationExtension', False)\n",
        "    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
        "\n",
        "def save_diagnostics(driver, filename_prefix):\n",
        "    \"\"\"Salva screenshot e HTML para depuração.\"\"\"\n",
        "    driver.save_screenshot(f\"{filename_prefix}_captura.png\")\n",
        "    with open(f\"{filename_prefix}_pagina.html\", 'w', encoding='utf-8') as f:\n",
        "        f.write(driver.page_source)\n",
        "    print(f\"--- [DIAGNÓSTICO] Arquivos de erro salvos como '{filename_prefix}_...'\")\n",
        "\n",
        "def parse_relative_date(date_str, timezone):\n",
        "    \"\"\"\n",
        "    Converte strings como 'há 3 horas' ou '19/10/2025' em um datetime.\n",
        "    VERSÃO APRIMORADA com mais formatos e debug.\n",
        "    \"\"\"\n",
        "    if not date_str:\n",
        "        print(f\"[PARSE_DATE] Data vazia recebida\")\n",
        "        return None\n",
        "\n",
        "    now = datetime.now(timezone)\n",
        "    date_str_lower = date_str.lower().strip()\n",
        "\n",
        "    # Debug: mostra o que está sendo parseado\n",
        "    print(f\"[PARSE_DATE] Tentando parsear: '{date_str_lower}'\")\n",
        "\n",
        "    try:\n",
        "        # Formato: \"agora mesmo\", \"agora\"\n",
        "        if 'agora' in date_str_lower:\n",
        "            return now\n",
        "\n",
        "        # Formato: \"há X minuto(s)\"\n",
        "        if 'minuto' in date_str_lower:\n",
        "            match = re.search(r'(\\d+)', date_str)\n",
        "            if match:\n",
        "                minutes = int(match.group(1))\n",
        "                return now - timedelta(minutes=minutes)\n",
        "\n",
        "        # Formato: \"há X hora(s)\"\n",
        "        if 'hora' in date_str_lower:\n",
        "            match = re.search(r'(\\d+)', date_str)\n",
        "            if match:\n",
        "                hours = int(match.group(1))\n",
        "                return now - timedelta(hours=hours)\n",
        "\n",
        "        # Formato: \"ontem\"\n",
        "        if 'ontem' in date_str_lower:\n",
        "            return now - timedelta(days=1)\n",
        "\n",
        "        # Formato: \"há X dia(s)\"\n",
        "        if 'dia' in date_str_lower and 'há' in date_str_lower:\n",
        "            match = re.search(r'(\\d+)', date_str)\n",
        "            if match:\n",
        "                days = int(match.group(1))\n",
        "                return now - timedelta(days=days)\n",
        "\n",
        "        # Formato: \"DD/MM/YYYY\"\n",
        "        if '/' in date_str:\n",
        "            parsed_date = datetime.strptime(date_str_lower, '%d/%m/%Y')\n",
        "            return timezone.localize(parsed_date)\n",
        "\n",
        "        # Formato: \"DD/MM/YYYY HH:MM\" ou \"DD/MM/YY\"\n",
        "        date_patterns = [\n",
        "            r'(\\d{2})/(\\d{2})/(\\d{4})',  # DD/MM/YYYY\n",
        "            r'(\\d{2})/(\\d{2})/(\\d{2})',   # DD/MM/YY\n",
        "        ]\n",
        "        for pattern in date_patterns:\n",
        "            match = re.search(pattern, date_str)\n",
        "            if match:\n",
        "                try:\n",
        "                    if len(match.group(3)) == 2:  # Ano com 2 dígitos\n",
        "                        parsed_date = datetime.strptime(f\"{match.group(1)}/{match.group(2)}/20{match.group(3)}\", '%d/%m/%Y')\n",
        "                    else:\n",
        "                        parsed_date = datetime.strptime(f\"{match.group(1)}/{match.group(2)}/{match.group(3)}\", '%d/%m/%Y')\n",
        "                    return timezone.localize(parsed_date)\n",
        "                except ValueError:\n",
        "                    continue\n",
        "\n",
        "        print(f\"[PARSE_DATE] Formato não reconhecido: '{date_str_lower}'\")\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[PARSE_DATE] Erro ao parsear data '{date_str}': {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_date_from_element(noticia, timezone):\n",
        "    \"\"\"\n",
        "    Tenta múltiplas estratégias para extrair a data de publicação.\n",
        "    NOVA FUNÇÃO para ser mais agressiva na busca.\n",
        "    \"\"\"\n",
        "    date_selectors = [\n",
        "        ('div', 'widget--info__meta'),\n",
        "        ('span', 'widget--info__meta'),\n",
        "        ('time', None),\n",
        "        ('div', 'feed-post-datetime'),\n",
        "        ('span', 'feed-post-datetime'),\n",
        "    ]\n",
        "\n",
        "    for tag, class_name in date_selectors:\n",
        "        try:\n",
        "            if class_name:\n",
        "                date_element = noticia.find(tag, class_=class_name)\n",
        "            else:\n",
        "                date_element = noticia.find(tag)\n",
        "\n",
        "            if date_element:\n",
        "                # Tenta pegar o atributo datetime primeiro (mais confiável)\n",
        "                if date_element.has_attr('datetime'):\n",
        "                    date_str = date_element['datetime']\n",
        "                    print(f\"[EXTRACT_DATE] Encontrado datetime attribute: '{date_str}'\")\n",
        "                    try:\n",
        "                        return datetime.fromisoformat(date_str.replace('Z', '+00:00')).astimezone(timezone)\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                # Se não tiver datetime, pega o texto\n",
        "                date_str = date_element.text.strip()\n",
        "                if date_str:\n",
        "                    print(f\"[EXTRACT_DATE] Encontrado texto de data: '{date_str}'\")\n",
        "                    parsed_date = parse_relative_date(date_str, timezone)\n",
        "                    if parsed_date:\n",
        "                        return parsed_date\n",
        "        except Exception as e:\n",
        "            print(f\"[EXTRACT_DATE] Erro ao extrair de {tag}.{class_name}: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Se nenhum seletor funcionou, tenta buscar qualquer texto que pareça uma data\n",
        "    text_content = noticia.get_text()\n",
        "    date_patterns = [\n",
        "        r'há\\s+\\d+\\s+(minuto|hora|dia)s?',\n",
        "        r'\\d{2}/\\d{2}/\\d{4}',\n",
        "        r'ontem',\n",
        "        r'agora'\n",
        "    ]\n",
        "\n",
        "    for pattern in date_patterns:\n",
        "        match = re.search(pattern, text_content, re.IGNORECASE)\n",
        "        if match:\n",
        "            date_str = match.group(0)\n",
        "            print(f\"[EXTRACT_DATE] Encontrado via regex: '{date_str}'\")\n",
        "            parsed_date = parse_relative_date(date_str, timezone)\n",
        "            if parsed_date:\n",
        "                return parsed_date\n",
        "\n",
        "    print(f\"[EXTRACT_DATE] Nenhuma data encontrada para esta notícia\")\n",
        "    return None\n",
        "\n",
        "def scrape_g1(base_url):\n",
        "    \"\"\"\n",
        "    Versão aprimorada com melhor extração de datas.\n",
        "    \"\"\"\n",
        "    print(f\"\\n[G1] Coletando da URL base: {base_url}\")\n",
        "    driver = setup_driver()\n",
        "    wait = WebDriverWait(driver, 15)\n",
        "\n",
        "    NUMERO_DE_PAGINAS_TOTAIS = 6\n",
        "    noticias_coletadas_total = 0\n",
        "\n",
        "    try:\n",
        "        for page_num in range(1, NUMERO_DE_PAGINAS_TOTAIS + 1):\n",
        "            page_url = f\"{base_url}&page={page_num}\"\n",
        "            print(f\"\\n[G1] === Coletando dados da Página {page_num} ===\")\n",
        "\n",
        "            if page_num > 1:\n",
        "                old_page_html = driver.find_element(By.TAG_NAME, \"html\")\n",
        "\n",
        "            driver.get(page_url)\n",
        "\n",
        "            if page_num == 1:\n",
        "                try:\n",
        "                    WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, \"cookie-banner-lgpd-accept\"))).click()\n",
        "                    print(\"[G1] Banner de cookies aceito.\")\n",
        "                except TimeoutException:\n",
        "                    print(\"[G1] Banner de cookies não encontrado ou já aceito.\")\n",
        "\n",
        "            if page_num > 1:\n",
        "                print(f\"[G1] Esperando a página {page_num-1} desaparecer...\")\n",
        "                wait.until(EC.staleness_of(old_page_html))\n",
        "\n",
        "            content_selector_css = \"li.widget--info\"\n",
        "            print(f\"[G1] Esperando conteúdo da página {page_num}...\")\n",
        "            wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, content_selector_css)))\n",
        "\n",
        "            html_content = driver.page_source\n",
        "            soup = BeautifulSoup(html_content, 'html.parser')\n",
        "            noticias_na_pagina = soup.select(content_selector_css)\n",
        "\n",
        "            if not noticias_na_pagina:\n",
        "                print(\"[G1] Página sem notícias (ou seletor mudou). Interrompendo paginação.\")\n",
        "                break\n",
        "\n",
        "            print(f\"[G1] Encontradas {len(noticias_na_pagina)} notícias nesta página\")\n",
        "\n",
        "            for idx, noticia in enumerate(noticias_na_pagina, 1):\n",
        "                print(f\"\\n[G1] --- Processando notícia {idx}/{len(noticias_na_pagina)} ---\")\n",
        "\n",
        "                text_container = noticia.find('div', class_='widget--info__text-container')\n",
        "                if not text_container:\n",
        "                    print(\"[G1] Container de texto não encontrado\")\n",
        "                    continue\n",
        "\n",
        "                link_tag = text_container.find('a')\n",
        "                if not link_tag:\n",
        "                    print(\"[G1] Link não encontrado\")\n",
        "                    continue\n",
        "\n",
        "                titulo_tag = link_tag.find('div', class_='widget--info__title')\n",
        "                resumo_tag = link_tag.find('p', class_='widget--info__description')\n",
        "\n",
        "                # MUDANÇA CRÍTICA: Usa a nova função de extração\n",
        "                data_publicacao = extract_date_from_element(noticia, BR_TIMEZONE)\n",
        "\n",
        "                item = {\n",
        "                    'fonte': 'G1',\n",
        "                    'titulo': titulo_tag.text.strip() if titulo_tag else 'N/A',\n",
        "                    'resumo': resumo_tag.text.strip() if resumo_tag else 'N/A',\n",
        "                    'link': link_tag['href'],\n",
        "                    'horario_coleta': datetime.now(BR_TIMEZONE).isoformat(),\n",
        "                    'data_publicacao': data_publicacao\n",
        "                }\n",
        "\n",
        "                print(f\"[G1] ✓ Título: {item['titulo'][:50]}...\")\n",
        "                print(f\"[G1] ✓ Data publicação: {data_publicacao}\")\n",
        "\n",
        "                dados_coletados.append(item)\n",
        "\n",
        "            noticias_coletadas_pagina = len(noticias_na_pagina)\n",
        "            noticias_coletadas_total += noticias_coletadas_pagina\n",
        "            print(f\"\\n[G1] Página {page_num} concluída. {noticias_coletadas_pagina} notícias adicionadas.\")\n",
        "            time.sleep(1)\n",
        "\n",
        "    except TimeoutException:\n",
        "        print(f\"[G1] Condição de 'sem dados': Página {page_num} não carregou ou estava vazia. Encerrando coleta.\")\n",
        "    except Exception as e:\n",
        "        print(f\"[G1] ERRO INESPERADO: {e}\")\n",
        "        save_diagnostics(driver, f\"g1_erro_page_{page_num}\")\n",
        "    finally:\n",
        "        driver.quit()\n",
        "        print(f\"\\n[G1] Coleta finalizada. Total de {noticias_coletadas_total} notícias extraídas.\")\n",
        "\n",
        "\n",
        "def executar_coleta_automatizada():\n",
        "    print(\"\\n--- [RUN] Iniciando Coleta Automatizada ---\")\n",
        "    dados_coletados.clear()\n",
        "    scrape_g1(URL_G1_BASE)\n",
        "    print(\"\\n--- [RUN] Coleta finalizada ---\")\n",
        "\n",
        "    if dados_coletados:\n",
        "        df = pd.DataFrame(dados_coletados)\n",
        "        df = df.drop_duplicates(subset=['link'], keep='first')\n",
        "\n",
        "        # Estatísticas de captura de datas\n",
        "        total = len(df)\n",
        "        com_data = df['data_publicacao'].notna().sum()\n",
        "        sem_data = total - com_data\n",
        "\n",
        "        print(f\"\\n--- [ESTATÍSTICAS] ---\")\n",
        "        print(f\"Total de notícias: {total}\")\n",
        "        print(f\"Com data de publicação: {com_data} ({com_data/total*100:.1f}%)\")\n",
        "        print(f\"Sem data de publicação: {sem_data} ({sem_data/total*100:.1f}%)\")\n",
        "\n",
        "        return df\n",
        "    else:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# PASSO 4: EXECUÇÃO DA COLETA\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "df_output = executar_coleta_automatizada()\n",
        "\n",
        "if not df_output.empty:\n",
        "    print(\"\\n--- [OUTPUT] Coleta concluída. Exibindo 5 primeiros resultados: ---\")\n",
        "    try:\n",
        "        from IPython.display import display\n",
        "        display(df_output.head())\n",
        "    except (ImportError, NameError):\n",
        "        print(df_output.head())\n",
        "else:\n",
        "    print(\"\\n--- [OUTPUT] Nenhuma notícia nova foi coletada. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "25rNW-tSCzm2",
        "outputId": "62a9cf26-6850-46ea-b652-c8412b5f4ea7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- [SETUP] Instalando dependências do sistema e do Python ---\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "dpkg: dependency problems prevent configuration of google-chrome-stable:\n",
            " google-chrome-stable depends on libatk-bridge2.0-0 (>= 2.5.3); however:\n",
            "  Package libatk-bridge2.0-0 is not installed.\n",
            " google-chrome-stable depends on libatk1.0-0 (>= 2.11.90); however:\n",
            "  Package libatk1.0-0 is not installed.\n",
            " google-chrome-stable depends on libatspi2.0-0 (>= 2.9.90); however:\n",
            "  Package libatspi2.0-0 is not installed.\n",
            " google-chrome-stable depends on libxcomposite1 (>= 1:0.4.4-1); however:\n",
            "  Package libxcomposite1 is not installed.\n",
            "\n",
            "dpkg: error processing package google-chrome-stable (--install):\n",
            " dependency problems - leaving unconfigured\n",
            "Errors were encountered while processing:\n",
            " google-chrome-stable\n",
            "--- [SETUP] Instalação concluída ---\n",
            "\n",
            "--- [INIT] Fase 1: Bibliotecas importadas ---\n",
            "\n",
            "--- [RUN] Iniciando Coleta Automatizada ---\n",
            "\n",
            "[G1] Coletando da URL base: https://g1.globo.com/busca/?q=defesa%20civil%20campinas%20piracicaba&order=recent&period=7d\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "WebDriverException",
          "evalue": "Message: unknown error: Chrome failed to start: exited abnormally.\n  (unknown error: DevToolsActivePort file doesn't exist)\n  (The process started from chrome location /opt/google/chrome/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\nStacktrace:\n#0 0x5be0853074e3 <unknown>\n#1 0x5be085036c76 <unknown>\n#2 0x5be08505fd78 <unknown>\n#3 0x5be08505c029 <unknown>\n#4 0x5be08509accc <unknown>\n#5 0x5be08509a47f <unknown>\n#6 0x5be085091de3 <unknown>\n#7 0x5be0850672dd <unknown>\n#8 0x5be08506834e <unknown>\n#9 0x5be0852c73e4 <unknown>\n#10 0x5be0852cb3d7 <unknown>\n#11 0x5be0852d5b20 <unknown>\n#12 0x5be0852cc023 <unknown>\n#13 0x5be08529a1aa <unknown>\n#14 0x5be0852f06b8 <unknown>\n#15 0x5be0852f0847 <unknown>\n#16 0x5be085300243 <unknown>\n#17 0x79eb98837ac3 <unknown>\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1872220159.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m \u001b[0mdf_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutar_coleta_automatizada\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdf_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1872220159.py\u001b[0m in \u001b[0;36mexecutar_coleta_automatizada\u001b[0;34m()\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- [RUN] Iniciando Coleta Automatizada ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0mdados_coletados\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0mscrape_g1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL_G1_BASE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- [RUN] Coleta finalizada ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1872220159.py\u001b[0m in \u001b[0;36mscrape_g1\u001b[0;34m(base_url)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \"\"\"\n\u001b[1;32m    203\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n[G1] Coletando da URL base: {base_url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0mwait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWebDriverWait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1872220159.py\u001b[0m in \u001b[0;36msetup_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_experimental_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"excludeSwitches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"enable-automation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_experimental_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'useAutomationExtension'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mService\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mChromeDriverManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_diagnostics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mbrowser_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDesiredCapabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHROME\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"browserName\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mvendor_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"goog\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/selenium/webdriver/chromium/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command_executor, keep_alive, file_detector, options, locator_converter, web_element_cls, client_config)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_authenticator_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fedcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFedCM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mstart_session\u001b[0;34m(self, capabilities)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mcaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_caps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEW_SESSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sessionId\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"capabilities\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alert\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mWebDriverException\u001b[0m: Message: unknown error: Chrome failed to start: exited abnormally.\n  (unknown error: DevToolsActivePort file doesn't exist)\n  (The process started from chrome location /opt/google/chrome/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\nStacktrace:\n#0 0x5be0853074e3 <unknown>\n#1 0x5be085036c76 <unknown>\n#2 0x5be08505fd78 <unknown>\n#3 0x5be08505c029 <unknown>\n#4 0x5be08509accc <unknown>\n#5 0x5be08509a47f <unknown>\n#6 0x5be085091de3 <unknown>\n#7 0x5be0850672dd <unknown>\n#8 0x5be08506834e <unknown>\n#9 0x5be0852c73e4 <unknown>\n#10 0x5be0852cb3d7 <unknown>\n#11 0x5be0852d5b20 <unknown>\n#12 0x5be0852cc023 <unknown>\n#13 0x5be08529a1aa <unknown>\n#14 0x5be0852f06b8 <unknown>\n#15 0x5be0852f0847 <unknown>\n#16 0x5be085300243 <unknown>\n#17 0x79eb98837ac3 <unknown>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limpeza e Estruturação"
      ],
      "metadata": {
        "id": "ewH5wfMhHtBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "# Verifique se o DataFrame 'df_output' não está vazio antes de processar\n",
        "if 'df_output' in locals() and not df_output.empty:\n",
        "    def classificar_risco(row):\n",
        "        \"\"\"\n",
        "        Analisa o título e o resumo de uma notícia para atribuir um nível de risco.\n",
        "        \"\"\"\n",
        "        # Consolida o texto em um único campo e converte para minúsculas\n",
        "        texto_completo = f\"{row['titulo']} {row['resumo']}\".lower()\n",
        "\n",
        "        # Nível 5 (Crítico): Risco iminente e de grande escala\n",
        "        if re.search(r'estiagem|enchente|cheia', texto_completo):\n",
        "            return 5\n",
        "\n",
        "        # Nível 4 (Alto): Impacto direto em sistemas críticos\n",
        "        if re.search(r'cantareira|qualidade da [aá]gua', texto_completo):\n",
        "            return 4\n",
        "\n",
        "        # Nível 3 (Médio): Eventos meteorológicos severos\n",
        "        if re.search(r'tempestade|chuva forte', texto_completo):\n",
        "            return 3\n",
        "\n",
        "        # Nível 2 (Baixo): Eventos meteorológicos comuns\n",
        "        if re.search(r'chuva', texto_completo):\n",
        "            return 2\n",
        "\n",
        "        # Nível 1 (Atenção): Eventos de menor impacto potencial\n",
        "        if re.search(r'vento|ventania', texto_completo):\n",
        "            return 1\n",
        "\n",
        "        # Nível 0 (Informativo): Nenhum risco operacional identificado\n",
        "        return 0\n",
        "\n",
        "    print(\"--- [ANÁLISE] Iniciando a classificação de risco das notícias coletadas ---\")\n",
        "\n",
        "    # Aplica a função de classificação para criar a nova coluna 'nivel_risco'\n",
        "    df_output['nivel_risco'] = df_output.apply(classificar_risco, axis=1)\n",
        "\n",
        "    # Ordena o DataFrame pelo nível de risco, do mais alto para o mais baixo\n",
        "    df_priorizado = df_output.sort_values(by='nivel_risco', ascending=False)\n",
        "\n",
        "    print(\"--- [ANÁLISE] Classificação concluída. Exibindo resultados priorizados: ---\")\n",
        "\n",
        "    # --- MUDANÇA: Adicionando 'data_publicacao' à exibição ---\n",
        "    colunas_exibicao = ['nivel_risco', 'fonte', 'data_publicacao', 'titulo', 'resumo', 'link', 'horario_coleta']\n",
        "\n",
        "    try:\n",
        "        from IPython.display import display\n",
        "        # Exibe o DataFrame com a nova coluna de data de publicação\n",
        "        display(df_priorizado[colunas_exibicao])\n",
        "    except (ImportError, NameError):\n",
        "        print(df_priorizado[colunas_exibicao])\n",
        "else:\n",
        "    print(\"--- [ANÁLISE] 'df_output' está vazio. Pulando etapa de classificação. ---\")"
      ],
      "metadata": {
        "id": "mAiMN6zEHk3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sync GCP BigQuery"
      ],
      "metadata": {
        "id": "4L05mLOikvJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adicione esta linha no início do seu script, junto com os outros !pip\n",
        "!pip install google-cloud-bigquery pandas-gbq -q"
      ],
      "metadata": {
        "id": "sXARcSrZky7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# PASSO 1: INSTALAR BIBLIOTECAS (se ainda não tiver feito)\n",
        "# ----------------------------------------------------------------------\n",
        "!pip install google-cloud-bigquery pandas-gbq -q\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# PASSO 2: AUTENTICAR E FAZER UPLOAD\n",
        "# ----------------------------------------------------------------------\n",
        "import pandas as pd\n",
        "from google.colab import auth\n",
        "import pandas_gbq\n",
        "from google.cloud import bigquery # Precisamos do cliente completo do BigQuery para o MERGE\n",
        "\n",
        "# Autentica o usuário para permitir o acesso ao Google Cloud\n",
        "print(\"--- [AUTH] Autenticando para acesso ao BigQuery ---\")\n",
        "auth.authenticate_user()\n",
        "print(\"--- [AUTH] Autenticação concluída com sucesso ---\")\n",
        "\n",
        "\n",
        "# Verifique se o DataFrame df_priorizado existe e não está vazio\n",
        "if 'df_priorizado' in locals() and not df_priorizado.empty:\n",
        "    print(\"\\n--- [BIGQUERY] Iniciando processo de upload ---\")\n",
        "\n",
        "    # 1. Defina os nomes do projeto e das tabelas\n",
        "    project_id = \"bacias-pcj\"\n",
        "    main_table_id = \"scrapping.noticias\"        # Tabela principal, de produção\n",
        "    staging_table_id = \"scrapping.noticias_staging\" # Tabela de rascunho/temporária\n",
        "\n",
        "    # 2. Crie uma cópia para evitar alterar o DataFrame original\n",
        "    df_to_upload = df_priorizado.copy()\n",
        "\n",
        "    # 3. Garanta que as colunas de data estão no formato correto\n",
        "    df_to_upload['horario_coleta'] = pd.to_datetime(df_to_upload['horario_coleta'])\n",
        "    df_to_upload['data_publicacao'] = pd.to_datetime(df_to_upload['data_publicacao'])\n",
        "\n",
        "    # 4. Defina o schema (estrutura) da tabela\n",
        "    table_schema = [\n",
        "        {'name': 'nivel_risco', 'type': 'INTEGER'},\n",
        "        {'name': 'fonte', 'type': 'STRING'},\n",
        "        {'name': 'titulo', 'type': 'STRING'},\n",
        "        {'name': 'resumo', 'type': 'STRING'},\n",
        "        {'name': 'link', 'type': 'STRING'},\n",
        "        {'name': 'horario_coleta', 'type': 'TIMESTAMP'},\n",
        "        {'name': 'data_publicacao', 'type': 'TIMESTAMP'}\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # --- ETAPA A: UPLOAD PARA A TABELA DE STAGING (RASCUNHO) ---\n",
        "        print(f\"Enviando {len(df_to_upload)} registros para a tabela de staging: '{staging_table_id}'...\")\n",
        "        pandas_gbq.to_gbq(\n",
        "            df_to_upload,\n",
        "            destination_table=staging_table_id,\n",
        "            project_id=project_id,\n",
        "            if_exists='replace',\n",
        "            table_schema=table_schema\n",
        "        )\n",
        "        print(\"Upload para staging concluído com sucesso.\")\n",
        "\n",
        "        # --- ETAPA B: EXECUTAR O MERGE NA TABELA PRINCIPAL ---\n",
        "        print(f\"Executando MERGE da staging para a tabela principal: '{main_table_id}'...\")\n",
        "\n",
        "        client = bigquery.Client(project=project_id)\n",
        "\n",
        "        # --- MUDANÇA CRÍTICA: Adicionando a lógica WHEN MATCHED ---\n",
        "        merge_sql = f\"\"\"\n",
        "        MERGE `{project_id}.{main_table_id}` T\n",
        "        USING `{project_id}.{staging_table_id}` S\n",
        "        ON T.link = S.link\n",
        "\n",
        "        -- Se o link já existe, MAS a data_publicacao está NULA, atualize-a.\n",
        "        WHEN MATCHED AND T.data_publicacao IS NULL THEN\n",
        "          UPDATE SET T.data_publicacao = S.data_publicacao\n",
        "\n",
        "        -- Se o link é totalmente novo, insira a linha.\n",
        "        WHEN NOT MATCHED BY TARGET THEN\n",
        "          INSERT (nivel_risco, fonte, titulo, resumo, link, horario_coleta, data_publicacao)\n",
        "          VALUES(S.nivel_risco, S.fonte, S.titulo, S.resumo, S.link, S.horario_coleta, S.data_publicacao)\n",
        "        \"\"\"\n",
        "        # --- FIM DA MUDANÇA ---\n",
        "\n",
        "        query_job = client.query(merge_sql)\n",
        "        query_job.result()  # Espera a consulta terminar\n",
        "\n",
        "        print(f\"--- [BIGQUERY] MERGE concluído! {query_job.num_dml_affected_rows} linhas foram afetadas (inseridas ou atualizadas).\")\n",
        "        print(f\"--- [BIGQUERY] Sucesso! Pipeline de upload finalizado.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"--- [BIGQUERY] ERRO: Falha no pipeline de upload. Detalhes: {e}\")\n",
        "else:\n",
        "    print(\"\\n--- [BIGQUERY] DataFrame 'df_priorizado' não encontrado ou está vazio. Nenhum dado para enviar. ---\")"
      ],
      "metadata": {
        "id": "wmS8Dmj0k3wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CQ6KVbZW7t-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defesa Civil - Piracicaba"
      ],
      "metadata": {
        "id": "Fu-FVloB7v5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constantes\n"
      ],
      "metadata": {
        "id": "NmP8KT3G702F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BR_TIMEZONE = pytz.timezone('America/Sao_Paulo')\n",
        "URL_BASE = \"https://piracicaba.sp.gov.br/noticias/?competencia=defesa-civil\"\n",
        "HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
        "dados_coletados = []"
      ],
      "metadata": {
        "id": "ZvYDAndp7z5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scraping Functions"
      ],
      "metadata": {
        "id": "b5jN-k9G8Lnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_driver():\n",
        "    \"\"\"Configura o WebDriver com opções anti-detecção.\"\"\"\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    options.add_argument(f'user-agent={HEADERS[\"User-Agent\"]}')\n",
        "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
        "    options.add_experimental_option('useAutomationExtension', False)\n",
        "    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
        "\n",
        "def parse_date_piracicaba(date_str, timezone):\n",
        "    \"\"\"\n",
        "    Converte data do formato do site de Piracicaba (DD/MM/YYYY) em datetime.\n",
        "    \"\"\"\n",
        "    if not date_str:\n",
        "        print(f\"[PARSE_DATE] Data vazia recebida\")\n",
        "        return None\n",
        "\n",
        "    date_str_clean = date_str.strip()\n",
        "    print(f\"[PARSE_DATE] Tentando parsear: '{date_str_clean}'\")\n",
        "\n",
        "    try:\n",
        "        # Formato esperado: DD/MM/YYYY\n",
        "        if '/' in date_str_clean:\n",
        "            # Remove qualquer texto extra e pega apenas a data\n",
        "            match = re.search(r'(\\d{2}/\\d{2}/\\d{4})', date_str_clean)\n",
        "            if match:\n",
        "                date_only = match.group(1)\n",
        "                parsed_date = datetime.strptime(date_only, '%d/%m/%Y')\n",
        "                return timezone.localize(parsed_date)\n",
        "\n",
        "        print(f\"[PARSE_DATE] Formato não reconhecido: '{date_str_clean}'\")\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[PARSE_DATE] Erro ao parsear data '{date_str_clean}': {e}\")\n",
        "        return None\n",
        "\n",
        "def scrape_defesa_civil_piracicaba(base_url):\n",
        "    \"\"\"\n",
        "    Scraping específico para o site da Defesa Civil de Piracicaba.\n",
        "    Coleta múltiplas páginas de notícias.\n",
        "    \"\"\"\n",
        "    print(f\"\\n[DC_PIRACICABA] Coletando da URL: {base_url}\")\n",
        "    driver = setup_driver()\n",
        "    wait = WebDriverWait(driver, 15)\n",
        "\n",
        "    noticias_coletadas_total = 0\n",
        "    NUMERO_DE_PAGINAS = 5  # Há 5 páginas de notícias\n",
        "\n",
        "    try:\n",
        "        for page_num in range(1, NUMERO_DE_PAGINAS + 1):\n",
        "            # Monta a URL da página\n",
        "            if page_num == 1:\n",
        "                page_url = base_url\n",
        "            else:\n",
        "                page_url = f\"https://piracicaba.sp.gov.br/noticias/page/{page_num}/?competencia=defesa-civil\"\n",
        "\n",
        "            print(f\"\\n[DC_PIRACICABA] === Coletando PÁGINA {page_num}/{NUMERO_DE_PAGINAS} ===\")\n",
        "            print(f\"[DC_PIRACICABA] URL: {page_url}\")\n",
        "\n",
        "            driver.get(page_url)\n",
        "            print(\"[DC_PIRACICABA] Página carregada. Aguardando conteúdo...\")\n",
        "\n",
        "            # Aguarda o carregamento das notícias\n",
        "            time.sleep(3)\n",
        "\n",
        "            html_content = driver.page_source\n",
        "            soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "            # Encontrar todas as notícias\n",
        "            # Estrutura: div.card dentro de div.col-12\n",
        "            noticias_na_pagina = soup.select('div.col-12 > div.card')\n",
        "\n",
        "            if not noticias_na_pagina:\n",
        "                print(f\"[DC_PIRACICABA] Nenhuma notícia encontrada na página {page_num}. Encerrando coleta.\")\n",
        "                break\n",
        "\n",
        "            print(f\"[DC_PIRACICABA] Encontradas {len(noticias_na_pagina)} notícias na página {page_num}\")\n",
        "\n",
        "            for idx, card in enumerate(noticias_na_pagina, 1):\n",
        "                print(f\"[DC_PIRACICABA] --- Processando notícia {idx}/{len(noticias_na_pagina)} (Página {page_num}) ---\")\n",
        "\n",
        "            try:\n",
        "                # Link: dentro de a.stretched-link\n",
        "                link_tag = card.select_one('a.stretched-link')\n",
        "                if not link_tag or not link_tag.get('href'):\n",
        "                    print(\"[DC_PIRACICABA] Link não encontrado\")\n",
        "                    continue\n",
        "\n",
        "                link = link_tag['href']\n",
        "                # Garantir URL absoluta\n",
        "                if not link.startswith('http'):\n",
        "                    link = f\"https://piracicaba.sp.gov.br{link}\"\n",
        "\n",
        "                # Título: dentro de div.card-title h4\n",
        "                titulo_tag = card.select_one('div.card-title')\n",
        "                titulo = titulo_tag.text.strip() if titulo_tag else 'N/A'\n",
        "\n",
        "                # Resumo: dentro de div.card-text p\n",
        "                resumo_tag = card.select_one('div.card-text p')\n",
        "                resumo = resumo_tag.text.strip() if resumo_tag else 'N/A'\n",
        "\n",
        "                # Data: no final, dentro de div.card-text.text-muted com ícone de calendário\n",
        "                data_tag = card.select_one('div.card-text.text-muted.small')\n",
        "                data_publicacao = None\n",
        "\n",
        "                if data_tag:\n",
        "                    # Extrai apenas o texto da data (remove o ícone)\n",
        "                    date_text = data_tag.get_text(strip=True)\n",
        "                    # Remove o texto do ícone\n",
        "                    date_text = date_text.replace('Data da publicação', '').strip()\n",
        "                    print(f\"[DC_PIRACICABA] Data encontrada (texto): '{date_text}'\")\n",
        "                    data_publicacao = parse_date_piracicaba(date_text, BR_TIMEZONE)\n",
        "\n",
        "                item = {\n",
        "                    'fonte': 'DEFESA_CIVIL_PIRACICABA',\n",
        "                    'titulo': titulo,\n",
        "                    'resumo': resumo,\n",
        "                    'link': link,\n",
        "                    'horario_coleta': datetime.now(BR_TIMEZONE).isoformat(),\n",
        "                    'data_publicacao': data_publicacao\n",
        "                }\n",
        "\n",
        "                print(f\"[DC_PIRACICABA] ✓ Título: {titulo[:60]}...\")\n",
        "                print(f\"[DC_PIRACICABA] ✓ Data: {data_publicacao}\")\n",
        "                print(f\"[DC_PIRACICABA] ✓ Link: {link}\")\n",
        "\n",
        "                dados_coletados.append(item)\n",
        "                noticias_coletadas_total += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"[DC_PIRACICABA] Erro ao processar notícia {idx}: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                continue\n",
        "\n",
        "            print(f\"\\n[DC_PIRACICABA] Página {page_num} concluída. {len(noticias_na_pagina)} notícias processadas.\")\n",
        "            time.sleep(2)  # Pausa entre páginas\n",
        "\n",
        "        print(f\"\\n[DC_PIRACICABA] Coleta concluída. Total: {noticias_coletadas_total} notícias extraídas.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[DC_PIRACICABA] ERRO INESPERADO: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "    finally:\n",
        "        driver.quit()\n",
        "\n",
        "    return dados_coletados\n",
        "\n",
        "\n",
        "def executar_coleta_dc_piracicaba():\n",
        "    print(\"\\n=== [RUN] INICIANDO COLETA DEFESA CIVIL PIRACICABA ===\")\n",
        "    dados_coletados.clear()\n",
        "    scrape_defesa_civil_piracicaba(URL_BASE)\n",
        "    print(\"\\n=== [RUN] COLETA FINALIZADA ===\")\n",
        "\n",
        "    if dados_coletados:\n",
        "        df = pd.DataFrame(dados_coletados)\n",
        "        df = df.drop_duplicates(subset=['link'], keep='first')\n",
        "\n",
        "        total = len(df)\n",
        "        com_data = df['data_publicacao'].notna().sum()\n",
        "        sem_data = total - com_data\n",
        "\n",
        "        print(f\"\\n--- [ESTATÍSTICAS] ---\")\n",
        "        print(f\"Total de notícias: {total}\")\n",
        "        print(f\"Com data de publicação: {com_data} ({com_data/total*100:.1f}%)\")\n",
        "        print(f\"Sem data de publicação: {sem_data} ({sem_data/total*100:.1f}%)\")\n",
        "\n",
        "        return df\n",
        "    else:\n",
        "        return pd.DataFrame()\n"
      ],
      "metadata": {
        "id": "7UR3Xqnt8QNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collection"
      ],
      "metadata": {
        "id": "xw8nIWNt8djz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_output = executar_coleta_dc_piracicaba()\n",
        "\n",
        "if not df_output.empty:\n",
        "    print(\"\\n--- [OUTPUT] Coleta concluída. Exibindo primeiros resultados: ---\")\n",
        "    try:\n",
        "        from IPython.display import display\n",
        "        display(df_output.head(10))\n",
        "    except (ImportError, NameError):\n",
        "        print(df_output.head(10))\n",
        "else:\n",
        "    print(\"\\n--- [OUTPUT] Nenhuma notícia foi coletada. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb0g0jEs8jGO",
        "outputId": "141c0a4d-b759-42a2-9974-02c71ac24b17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== [RUN] INICIANDO COLETA DEFESA CIVIL PIRACICABA ===\n",
            "\n",
            "[DC_PIRACICABA] Coletando da URL: https://piracicaba.sp.gov.br/noticias/?competencia=defesa-civil\n",
            "\n",
            "[DC_PIRACICABA] === Coletando PÁGINA 1/5 ===\n",
            "[DC_PIRACICABA] URL: https://piracicaba.sp.gov.br/noticias/?competencia=defesa-civil\n",
            "[DC_PIRACICABA] Página carregada. Aguardando conteúdo...\n",
            "[DC_PIRACICABA] Encontradas 10 notícias na página 1\n",
            "[DC_PIRACICABA] --- Processando notícia 1/10 (Página 1) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 2/10 (Página 1) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 3/10 (Página 1) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 4/10 (Página 1) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 5/10 (Página 1) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 6/10 (Página 1) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 7/10 (Página 1) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 8/10 (Página 1) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 9/10 (Página 1) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 10/10 (Página 1) ---\n",
            "[DC_PIRACICABA] Data encontrada (texto): '22/05/2025'\n",
            "[PARSE_DATE] Tentando parsear: '22/05/2025'\n",
            "[DC_PIRACICABA] ✓ Título: Maio Amarelo: simulado alerta sobre gravidade em acidentes d...\n",
            "[DC_PIRACICABA] ✓ Data: 2025-05-22 00:00:00-03:00\n",
            "[DC_PIRACICABA] ✓ Link: https://piracicaba.sp.gov.br/noticias/maio-amarelo-simulado-alerta-sobre-gravidade-em-acidentes-de-transito/\n",
            "\n",
            "[DC_PIRACICABA] Página 1 concluída. 10 notícias processadas.\n",
            "\n",
            "[DC_PIRACICABA] === Coletando PÁGINA 2/5 ===\n",
            "[DC_PIRACICABA] URL: https://piracicaba.sp.gov.br/noticias/page/2/?competencia=defesa-civil\n",
            "[DC_PIRACICABA] Página carregada. Aguardando conteúdo...\n",
            "[DC_PIRACICABA] Encontradas 10 notícias na página 2\n",
            "[DC_PIRACICABA] --- Processando notícia 1/10 (Página 2) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 2/10 (Página 2) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 3/10 (Página 2) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 4/10 (Página 2) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 5/10 (Página 2) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 6/10 (Página 2) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 7/10 (Página 2) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 8/10 (Página 2) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 9/10 (Página 2) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 10/10 (Página 2) ---\n",
            "[DC_PIRACICABA] Data encontrada (texto): '06/09/2024'\n",
            "[PARSE_DATE] Tentando parsear: '06/09/2024'\n",
            "[DC_PIRACICABA] ✓ Título: Piracicaba cria Comitê Florestal para combate a incêndios...\n",
            "[DC_PIRACICABA] ✓ Data: 2024-09-06 00:00:00-03:00\n",
            "[DC_PIRACICABA] ✓ Link: https://piracicaba.sp.gov.br/noticias/piracicaba-cria-comite-florestal-para-combate-a-incendios/\n",
            "\n",
            "[DC_PIRACICABA] Página 2 concluída. 10 notícias processadas.\n",
            "\n",
            "[DC_PIRACICABA] === Coletando PÁGINA 3/5 ===\n",
            "[DC_PIRACICABA] URL: https://piracicaba.sp.gov.br/noticias/page/3/?competencia=defesa-civil\n",
            "[DC_PIRACICABA] Página carregada. Aguardando conteúdo...\n",
            "[DC_PIRACICABA] Encontradas 10 notícias na página 3\n",
            "[DC_PIRACICABA] --- Processando notícia 1/10 (Página 3) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 2/10 (Página 3) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 3/10 (Página 3) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 4/10 (Página 3) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 5/10 (Página 3) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 6/10 (Página 3) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 7/10 (Página 3) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 8/10 (Página 3) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 9/10 (Página 3) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 10/10 (Página 3) ---\n",
            "[DC_PIRACICABA] Data encontrada (texto): '15/01/2024'\n",
            "[PARSE_DATE] Tentando parsear: '15/01/2024'\n",
            "[DC_PIRACICABA] ✓ Título: Prefeitura realiza limpeza de comportas e Canal do Mirante r...\n",
            "[DC_PIRACICABA] ✓ Data: 2024-01-15 00:00:00-03:00\n",
            "[DC_PIRACICABA] ✓ Link: https://piracicaba.sp.gov.br/noticias/prefeitura-realiza-limpeza-de-comportas-e-canal-do-mirante-recebe-agua-2/\n",
            "\n",
            "[DC_PIRACICABA] Página 3 concluída. 10 notícias processadas.\n",
            "\n",
            "[DC_PIRACICABA] === Coletando PÁGINA 4/5 ===\n",
            "[DC_PIRACICABA] URL: https://piracicaba.sp.gov.br/noticias/page/4/?competencia=defesa-civil\n",
            "[DC_PIRACICABA] Página carregada. Aguardando conteúdo...\n",
            "[DC_PIRACICABA] Encontradas 10 notícias na página 4\n",
            "[DC_PIRACICABA] --- Processando notícia 1/10 (Página 4) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 2/10 (Página 4) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 3/10 (Página 4) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 4/10 (Página 4) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 5/10 (Página 4) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 6/10 (Página 4) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 7/10 (Página 4) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 8/10 (Página 4) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 9/10 (Página 4) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 10/10 (Página 4) ---\n",
            "[DC_PIRACICABA] Data encontrada (texto): '05/10/2023'\n",
            "[PARSE_DATE] Tentando parsear: '05/10/2023'\n",
            "[DC_PIRACICABA] ✓ Título: Temporal causou queda de mais de 30 árvores; força-tarefa da...\n",
            "[DC_PIRACICABA] ✓ Data: 2023-10-05 00:00:00-03:00\n",
            "[DC_PIRACICABA] ✓ Link: https://piracicaba.sp.gov.br/noticias/temporal-causou-queda-de-mais-de-30-arvores-forca-tarefa-da-prefeitura-segue-nos-bairros-atingidos/\n",
            "\n",
            "[DC_PIRACICABA] Página 4 concluída. 10 notícias processadas.\n",
            "\n",
            "[DC_PIRACICABA] === Coletando PÁGINA 5/5 ===\n",
            "[DC_PIRACICABA] URL: https://piracicaba.sp.gov.br/noticias/page/5/?competencia=defesa-civil\n",
            "[DC_PIRACICABA] Página carregada. Aguardando conteúdo...\n",
            "[DC_PIRACICABA] Encontradas 4 notícias na página 5\n",
            "[DC_PIRACICABA] --- Processando notícia 1/4 (Página 5) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 2/4 (Página 5) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 3/4 (Página 5) ---\n",
            "[DC_PIRACICABA] --- Processando notícia 4/4 (Página 5) ---\n",
            "[DC_PIRACICABA] Data encontrada (texto): '28/09/2023'\n",
            "[PARSE_DATE] Tentando parsear: '28/09/2023'\n",
            "[DC_PIRACICABA] ✓ Título: Prefeitura realiza força-tarefa para minimizar efeitos do te...\n",
            "[DC_PIRACICABA] ✓ Data: 2023-09-28 00:00:00-03:00\n",
            "[DC_PIRACICABA] ✓ Link: https://piracicaba.sp.gov.br/noticias/prefeitura-realiza-forca-tarefa-para-minimizar-efeitos-do-temporal-dados-parciais-apontam-queda-de-60-arvores/\n",
            "\n",
            "[DC_PIRACICABA] Página 5 concluída. 4 notícias processadas.\n",
            "\n",
            "[DC_PIRACICABA] Coleta concluída. Total: 5 notícias extraídas.\n",
            "\n",
            "=== [RUN] COLETA FINALIZADA ===\n",
            "\n",
            "--- [ESTATÍSTICAS] ---\n",
            "Total de notícias: 5\n",
            "Com data de publicação: 5 (100.0%)\n",
            "Sem data de publicação: 0 (0.0%)\n",
            "\n",
            "--- [OUTPUT] Coleta concluída. Exibindo primeiros resultados: ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                     fonte                                             titulo  \\\n",
              "0  DEFESA_CIVIL_PIRACICABA  Maio Amarelo: simulado alerta sobre gravidade ...   \n",
              "1  DEFESA_CIVIL_PIRACICABA  Piracicaba cria Comitê Florestal para combate ...   \n",
              "2  DEFESA_CIVIL_PIRACICABA  Prefeitura realiza limpeza de comportas e Cana...   \n",
              "3  DEFESA_CIVIL_PIRACICABA  Temporal causou queda de mais de 30 árvores; f...   \n",
              "4  DEFESA_CIVIL_PIRACICABA  Prefeitura realiza força-tarefa para minimizar...   \n",
              "\n",
              "                                              resumo  \\\n",
              "0  Ação aconteceu no Centro da cidade na manhã de...   \n",
              "1  Encontro reuniu representantes do poder Execut...   \n",
              "2  Foram retirados aproximadamente dois caminhões...   \n",
              "3  Em uma semana, ventos derrubaram mais de 160 á...   \n",
              "4  Equipes trabalham desde ontem; bairros mais at...   \n",
              "\n",
              "                                                link  \\\n",
              "0  https://piracicaba.sp.gov.br/noticias/maio-ama...   \n",
              "1  https://piracicaba.sp.gov.br/noticias/piracica...   \n",
              "2  https://piracicaba.sp.gov.br/noticias/prefeitu...   \n",
              "3  https://piracicaba.sp.gov.br/noticias/temporal...   \n",
              "4  https://piracicaba.sp.gov.br/noticias/prefeitu...   \n",
              "\n",
              "                     horario_coleta           data_publicacao  \n",
              "0  2025-10-28T21:01:24.439354-03:00 2025-05-22 00:00:00-03:00  \n",
              "1  2025-10-28T21:01:33.905474-03:00 2024-09-06 00:00:00-03:00  \n",
              "2  2025-10-28T21:01:40.798693-03:00 2024-01-15 00:00:00-03:00  \n",
              "3  2025-10-28T21:01:48.175198-03:00 2023-10-05 00:00:00-03:00  \n",
              "4  2025-10-28T21:01:54.881009-03:00 2023-09-28 00:00:00-03:00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21b3ed40-f2fd-40fb-ab15-2e084f2da62e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fonte</th>\n",
              "      <th>titulo</th>\n",
              "      <th>resumo</th>\n",
              "      <th>link</th>\n",
              "      <th>horario_coleta</th>\n",
              "      <th>data_publicacao</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DEFESA_CIVIL_PIRACICABA</td>\n",
              "      <td>Maio Amarelo: simulado alerta sobre gravidade ...</td>\n",
              "      <td>Ação aconteceu no Centro da cidade na manhã de...</td>\n",
              "      <td>https://piracicaba.sp.gov.br/noticias/maio-ama...</td>\n",
              "      <td>2025-10-28T21:01:24.439354-03:00</td>\n",
              "      <td>2025-05-22 00:00:00-03:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DEFESA_CIVIL_PIRACICABA</td>\n",
              "      <td>Piracicaba cria Comitê Florestal para combate ...</td>\n",
              "      <td>Encontro reuniu representantes do poder Execut...</td>\n",
              "      <td>https://piracicaba.sp.gov.br/noticias/piracica...</td>\n",
              "      <td>2025-10-28T21:01:33.905474-03:00</td>\n",
              "      <td>2024-09-06 00:00:00-03:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DEFESA_CIVIL_PIRACICABA</td>\n",
              "      <td>Prefeitura realiza limpeza de comportas e Cana...</td>\n",
              "      <td>Foram retirados aproximadamente dois caminhões...</td>\n",
              "      <td>https://piracicaba.sp.gov.br/noticias/prefeitu...</td>\n",
              "      <td>2025-10-28T21:01:40.798693-03:00</td>\n",
              "      <td>2024-01-15 00:00:00-03:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DEFESA_CIVIL_PIRACICABA</td>\n",
              "      <td>Temporal causou queda de mais de 30 árvores; f...</td>\n",
              "      <td>Em uma semana, ventos derrubaram mais de 160 á...</td>\n",
              "      <td>https://piracicaba.sp.gov.br/noticias/temporal...</td>\n",
              "      <td>2025-10-28T21:01:48.175198-03:00</td>\n",
              "      <td>2023-10-05 00:00:00-03:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DEFESA_CIVIL_PIRACICABA</td>\n",
              "      <td>Prefeitura realiza força-tarefa para minimizar...</td>\n",
              "      <td>Equipes trabalham desde ontem; bairros mais at...</td>\n",
              "      <td>https://piracicaba.sp.gov.br/noticias/prefeitu...</td>\n",
              "      <td>2025-10-28T21:01:54.881009-03:00</td>\n",
              "      <td>2023-09-28 00:00:00-03:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21b3ed40-f2fd-40fb-ab15-2e084f2da62e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21b3ed40-f2fd-40fb-ab15-2e084f2da62e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21b3ed40-f2fd-40fb-ab15-2e084f2da62e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-96e94b21-cf97-4aa8-b1a8-a7b622ed000a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-96e94b21-cf97-4aa8-b1a8-a7b622ed000a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-96e94b21-cf97-4aa8-b1a8-a7b622ed000a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"\\\\n--- [OUTPUT] Nenhuma not\\u00edcia foi coletada\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"fonte\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"DEFESA_CIVIL_PIRACICABA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"titulo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Piracicaba cria Comit\\u00ea Florestal para combate a inc\\u00eandios\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resumo\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Encontro reuniu representantes do poder Executivo, Bombeiros, Defesa Civil, for\\u00e7as de seguran\\u00e7a, associa\\u00e7\\u00f5es e empresas que atuam na cidade e regi\\u00e3o\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"https://piracicaba.sp.gov.br/noticias/piracicaba-cria-comite-florestal-para-combate-a-incendios/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"horario_coleta\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2025-10-28T21:01:33.905474-03:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_publicacao\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-09-28 00:00:00-03:00\",\n        \"max\": \"2025-05-22 00:00:00-03:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2024-09-06 00:00:00-03:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sync BQ"
      ],
      "metadata": {
        "id": "qyOBahMK_SJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not df_output.empty:\n",
        "    print(\"\\n=== [BIGQUERY] INICIANDO SINCRONIZAÇÃO ===\")\n",
        "\n",
        "    from google.colab import auth\n",
        "    import pandas_gbq\n",
        "    from google.cloud import bigquery\n",
        "\n",
        "    # Autentica\n",
        "    print(\"--- [AUTH] Autenticando para acesso ao BigQuery ---\")\n",
        "    auth.authenticate_user()\n",
        "    print(\"--- [AUTH] Autenticação concluída ---\")\n",
        "\n",
        "    # Configurações\n",
        "    project_id = \"bacias-pcj\"\n",
        "    main_table_id = \"scrapping.dc_piracicaba\"\n",
        "    staging_table_id = \"scrapping.dc_piracicaba_staging\"\n",
        "\n",
        "    # Prepara DataFrame\n",
        "    df_to_upload = df_output.copy()\n",
        "    df_to_upload['horario_coleta'] = pd.to_datetime(df_to_upload['horario_coleta'])\n",
        "    df_to_upload['data_publicacao'] = pd.to_datetime(df_to_upload['data_publicacao'])\n",
        "\n",
        "    # Schema da tabela\n",
        "    table_schema = [\n",
        "        {'name': 'fonte', 'type': 'STRING'},\n",
        "        {'name': 'titulo', 'type': 'STRING'},\n",
        "        {'name': 'resumo', 'type': 'STRING'},\n",
        "        {'name': 'link', 'type': 'STRING'},\n",
        "        {'name': 'horario_coleta', 'type': 'TIMESTAMP'},\n",
        "        {'name': 'data_publicacao', 'type': 'TIMESTAMP'}\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # Upload para staging\n",
        "        print(f\"\\n[BIGQUERY] Enviando {len(df_to_upload)} registros para staging: '{staging_table_id}'...\")\n",
        "        pandas_gbq.to_gbq(\n",
        "            df_to_upload,\n",
        "            destination_table=staging_table_id,\n",
        "            project_id=project_id,\n",
        "            if_exists='replace',\n",
        "            table_schema=table_schema\n",
        "        )\n",
        "        print(\"[BIGQUERY] ✓ Upload para staging concluído\")\n",
        "\n",
        "        # Executar MERGE\n",
        "        print(f\"\\n[BIGQUERY] Executando MERGE para tabela principal: '{main_table_id}'...\")\n",
        "\n",
        "        client = bigquery.Client(project=project_id)\n",
        "\n",
        "        merge_sql = f\"\"\"\n",
        "        MERGE `{project_id}.{main_table_id}` T\n",
        "        USING `{project_id}.{staging_table_id}` S\n",
        "        ON T.link = S.link\n",
        "\n",
        "        -- Se o link já existe MAS a data_publicacao está NULA, atualize-a\n",
        "        WHEN MATCHED AND T.data_publicacao IS NULL THEN\n",
        "          UPDATE SET T.data_publicacao = S.data_publicacao\n",
        "\n",
        "        -- Se o link é totalmente novo, insira a linha\n",
        "        WHEN NOT MATCHED BY TARGET THEN\n",
        "          INSERT (fonte, titulo, resumo, link, horario_coleta, data_publicacao)\n",
        "          VALUES(S.fonte, S.titulo, S.resumo, S.link, S.horario_coleta, S.data_publicacao)\n",
        "        \"\"\"\n",
        "\n",
        "        query_job = client.query(merge_sql)\n",
        "        query_job.result()\n",
        "\n",
        "        print(f\"[BIGQUERY] ✓ MERGE concluído! {query_job.num_dml_affected_rows} linhas afetadas\")\n",
        "        print(\"\\n=== [BIGQUERY] SINCRONIZAÇÃO FINALIZADA COM SUCESSO ===\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n[BIGQUERY] ❌ ERRO: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"\\n[BIGQUERY] Nenhum dado para sincronizar.\")"
      ],
      "metadata": {
        "id": "VcgZ2gBH_XQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13b6ce6-4271-4c38-bf12-5035a48e6939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== [BIGQUERY] INICIANDO SINCRONIZAÇÃO ===\n",
            "--- [AUTH] Autenticando para acesso ao BigQuery ---\n",
            "--- [AUTH] Autenticação concluída ---\n",
            "\n",
            "[BIGQUERY] Enviando 5 registros para staging: 'scrapping.dc_piracicaba_staging'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 8701.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BIGQUERY] ✓ Upload para staging concluído\n",
            "\n",
            "[BIGQUERY] Executando MERGE para tabela principal: 'scrapping.dc_piracicaba'...\n",
            "\n",
            "[BIGQUERY] ❌ ERRO: 404 Not found: Table bacias-pcj:scrapping.dc_piracicaba was not found in location US; reason: notFound, message: Not found: Table bacias-pcj:scrapping.dc_piracicaba was not found in location US\n",
            "\n",
            "Location: US\n",
            "Job ID: 011f5064-8b93-4ce7-beee-47001f1a16bd\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-235214199.py\", line 66, in <cell line: 0>\n",
            "    query_job.result()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\", line 1773, in result\n",
            "    while not is_job_done():\n",
            "              ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\", line 294, in retry_wrapped_func\n",
            "    return retry_target(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\", line 156, in retry_target\n",
            "    next_sleep = _retry_error_helper(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\", line 214, in _retry_error_helper\n",
            "    raise final_exc from source_exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\", line 147, in retry_target\n",
            "    result = target()\n",
            "             ^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\", line 1722, in is_job_done\n",
            "    raise job_failed_exception\n",
            "google.api_core.exceptions.NotFound: 404 Not found: Table bacias-pcj:scrapping.dc_piracicaba was not found in location US; reason: notFound, message: Not found: Table bacias-pcj:scrapping.dc_piracicaba was not found in location US\n",
            "\n",
            "Location: US\n",
            "Job ID: 011f5064-8b93-4ce7-beee-47001f1a16bd\n",
            "\n"
          ]
        }
      ]
    }
  ]
}